{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Cesta de Compras no Google Colab\n",
    "\n",
    "Este notebook executa o processo completo de Market Basket Analysis.\n",
    "**Instruções:**\n",
    "1.  Execute a primeira célula de código para instalar as bibliotecas necessárias.\n",
    "2.  Execute a segunda célula. Ela pedirá que você faça o upload do seu arquivo `kaggle.json` para autenticação.\n",
    "3.  Execute as células restantes em ordem para baixar os dados, prepará-los e realizar a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1: Instalar bibliotecas necessárias\n",
    "!pip install kagglehub mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2: Configurar a API do Kaggle\n",
    "print('Por favor, faça o upload do seu arquivo kaggle.json')\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Faz o upload\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Cria o diretório e move o arquivo para o local correto\n",
    "if 'kaggle.json' in uploaded:\n",
    "    print('Arquivo kaggle.json recebido!')\n",
    "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
    "    os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
    "    os.chmod('/root/.kaggle/kaggle.json', 600)\n",
    "    print('Credenciais do Kaggle configuradas com sucesso.')\n",
    "else:\n",
    "    print('Erro: o arquivo kaggle.json não foi encontrado no upload.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 3: Baixar os datasets\n",
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "DATASETS = {\n",
    "    \"raw_retail\": {\n",
    "        \"slug\": \"aslanahmedov/market-basket-analysis\",\n",
    "        \"target_dir\": \"./raw_retail_dataset\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def download_and_copy(slug, target_path):\n",
    "    print(f\"--- Processando: {slug} ---\")\n",
    "    try:\n",
    "        source_dir = kagglehub.dataset_download(slug)\n",
    "        print(f\"Download concluído. Arquivos de origem em: {source_dir}\")\n",
    "        os.makedirs(target_path, exist_ok=True)\n",
    "        shutil.copytree(source_dir, target_path, dirs_exist_ok=True)\n",
    "        print(f\"Arquivos copiados para {target_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao processar {slug}: {e}\")\n",
    "\n",
    "print(\"Iniciando o processo de download dos datasets...")\n",
    "for key, info in DATASETS.items():\n",
    "    download_and_copy(info[\"slug\"], info[\"target_dir\"])\n",
    "print(\"\nProcesso finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 4: Preparação e Limpeza dos Dados\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_CSV_PATH = './raw_retail_dataset/Assignment-1_Data.csv'\n",
    "\n",
    "print(f\"Iniciando a leitura de: {INPUT_CSV_PATH}\")\n",
    "df = pd.read_csv(INPUT_CSV_PATH, sep=';', decimal=',', encoding='utf-8-sig')\n",
    "print(\"Arquivo carregado com sucesso.\")\n",
    "\n",
    "print(\"Iniciando processo de limpeza...\")\n",
    "df.dropna(subset=['BillNo', 'Itemname'], inplace=True)\n",
    "df['BillNo'] = df['BillNo'].astype(str)\n",
    "df = df[~df['BillNo'].str.contains('C', na=False)]\n",
    "df = df[df['Quantity'] > 0]\n",
    "df['Itemname'] = df['Itemname'].str.strip()\n",
    "print(\"Limpeza inicial concluída.\")\n",
    "\n",
    "print(\"Agrupando itens por transação para formar as cestas...\")\n",
    "basket = df.groupby('BillNo')['Itemname'].apply(list)\n",
    "transactions_list = basket.tolist()\n",
    "print(f\"Foram encontradas {len(transactions_list)} transações únicas.\")\n",
    "\n",
    "print(\"\nProcesso de preparação de dados concluído! A variável 'transactions_list' está pronta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 5: Análise de Cesta de Compras (Apriori)\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "print(\"Codificando transações para o formato binário...\")\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions_list).transform(transactions_list)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(\"Codificação concluída.\")\n",
    "\n",
    "# Como o Colab tem mais memória, podemos usar o min_support original de 0.01\n",
    "print(\"Aplicando o algoritmo Apriori para encontrar itemsets frequentes (min_support=0.01)...\")\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.01, use_colnames=True)\n",
    "print(f\"Encontrados {len(frequent_itemsets)} itemsets frequentes.\")\n",
    "\n",
    "print(\"Gerando regras de associação a partir dos itemsets (min_confidence=0.2)...\")\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.2)\n",
    "print(f\"Encontradas {len(rules)} regras de associação.\")\n",
    "\n",
    "if not rules.empty:\n",
    "    rules_sorted = rules.sort_values(by=['lift', 'confidence'], ascending=False)\n",
    "    \n",
    "    print(\"\n--- Top 20 Regras de Associação Mais Fortes ---")\n",
    "    print(\"Antecedents: Itens que o cliente comprou.\")\n",
    "    print(\"Consequents: Itens que o cliente provavelmente comprará em seguida.\")\n",
    "    print(\"Lift: Quão mais provável é a compra do consequente dado o antecedente.\")\n",
    "    print(\"Confidence: A probabilidade de o consequente ser comprado se o antecedente foi comprado.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    display(rules_sorted.head(20))\n",
    "else:\n",
    "    print(\"\nNenhuma regra de associação encontrada com os parâmetros definidos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}